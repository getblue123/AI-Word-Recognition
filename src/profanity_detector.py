# profanity_detector.py - é«’è©±æª¢æ¸¬æ¨¡çµ„
import re
from typing import List, Dict


class ProfanityDetector:
    """é«’è©±æª¢æ¸¬å™¨"""
    
    def __init__(self):
        # é«’è©±è©žåº« (åŒ…å«ä¸åŒé•·åº¦)
        self.profanity_words = {
            # ä¸€å­—é«’è©±
            "å¹¹": ["beep"], 
            "ç”˜": ["beep"],
            "å¹²": ["beep"],

            # äºŒå­—é«’è©±
            "å¹¹ä½ ": ["beep"],
            "æ“ä½ ": ["beep"],
            "é åŒ—": ["beep"],
            
            # ä¸‰å­—é«’è©±
            "å¹¹ä½ å¨˜": ["beep"],
            "æ“ä½ åª½": ["beep"],
            "è¡ä¸‰å°": ["beep"],
            "ç”˜éœ–å¨˜": ["beep"],
            "å¹¹å“©å¨˜": ["beep"],
            "å¹¹å“©æ¶¼": ["beep"],
            "å¹¹å°¼å¨˜": ["beep"],
            "å¹¹ä½ æ¶¼": ["beep"],

            # å››å­—é«’è©±
            "å¹¹ä½ è€å¸«": ["beep"],
            "æ“ä½ å…¨å®¶": ["beep"],
            "å¹¹ä½ è€æ¯": ["beep"],
            "ç™½ç—´æ™ºéšœ": ["beep"],
            
            # äº”å­—é«’è©±
            "å¹¹ä½ å¨˜æ©ŸæŽ°": ["beep"],
            "æ“ä½ åª½çš„é€¼": ["beep"],

            # Test
            "ä½ å¥½æˆ‘æ˜¯Googleå°å§": ["beep"],
        }
        
        # æ“´å±•çš„é«’è©±æ¨¡å¼ - åŒ…å«å¯èƒ½çš„è®Šå½¢
        self.profanity_patterns = {
            "å¹¹ä½ å¨˜": [
                r"å¹¹.*ä½ .*å¨˜",      # å¹¹-ä½ -å¨˜ (æœ‰åœé “)
                r"å¹¹.*å¨˜",          # å¹¹-å¨˜ (çœç•¥ä½ )
                r"å¹².*ä½ .*å¨˜",      # éŒ¯å­—è­˜åˆ¥
                r"ä¹¾.*ä½ .*å¨˜",      # åŒéŸ³å­—
                r"å¹¹.*æ³¥.*å¨˜",      # å£éŸ³è®ŠåŒ–
                r"å¹¹.*å¦³.*å¨˜",      # æ³¨éŸ³è¼¸å…¥æ³•
            ],
            "æ“ä½ åª½": [
                r"æ“.*ä½ .*åª½",
                r"æ“.*å¦³.*åª½",
                r"è‰.*ä½ .*åª½",      # åŒéŸ³å­—
                r"æ“.*ä½ .*é¦¬",      # è«§éŸ³
                r"æ“.*åª½",
                r"æ“.*ä½ .*æ¯",
            ],
            "å¹¹ä½ è€å¸«": [
                r"å¹¹.*ä½ .*è€.*å¸«",
                r"å¹¹.*è€.*å¸«",
                r"ä¹¾.*ä½ .*è€.*å¸«",
                r"å¹¹.*æ³¥.*è€.*å¸«",
            ],
            "é åŒ—": [
                r"é .*åŒ—",
                r"è€ƒ.*åŒ—",
                r"é .*æ¯",
                r"cao.*bei",        # è‹±æ–‡è¼¸å…¥
            ]
        }
    
    def detect_profanity_basic(self, text: str) -> List[str]:
        """åŸºæœ¬é«’è©±æª¢æ¸¬"""
        found_profanity = []
        text_lower = text.lower()
        
        for profanity in self.profanity_words.keys():
            if profanity in text_lower:
                found_profanity.append(profanity)
        
        return found_profanity
    
    def detect_profanity_fuzzy(self, text: str) -> List[str]:
        """æ¨¡ç³ŠåŒ¹é…é«’è©±æª¢æ¸¬ - è™•ç†é‡éŸ³ã€å»¶é²ç­‰å•é¡Œ"""
        found_profanity = []
        text_clean = re.sub(r'[^\w\s]', '', text.lower())  # ç§»é™¤æ¨™é»žç¬¦è™Ÿ
        
        print(f"      æ¨¡ç³Šæª¢æ¸¬æ–‡å­—: ã€Œ{text_clean}ã€")
        
        for profanity, patterns in self.profanity_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_clean):
                    found_profanity.append(profanity)
                    print(f"      ðŸŽ¯ æ¨¡ç³ŠåŒ¹é…åˆ°: {profanity} (æ¨¡å¼: {pattern})")
                    break  # æ‰¾åˆ°ä¸€å€‹å°±è·³åˆ°ä¸‹å€‹é«’è©±
        
        return found_profanity
    
    def detect_profanity(self, text: str, use_fuzzy: bool = True) -> List[str]:
        """æª¢æ¸¬æ–‡å­—ä¸­çš„é«’è©±"""
        # åŸºæœ¬æª¢æ¸¬
        basic_results = self.detect_profanity_basic(text)
        
        if use_fuzzy:
            # æ¨¡ç³Šæª¢æ¸¬
            fuzzy_results = self.detect_profanity_fuzzy(text)
            # åˆä½µçµæžœä¸¦åŽ»é‡
            all_results = list(set(basic_results + fuzzy_results))
            return all_results
        
        return basic_results
    
    def add_custom_profanity(self, words: List[str]):
        """æ·»åŠ è‡ªå®šç¾©é«’è©±è©žåº«"""
        for word in words:
            self.profanity_words[word.lower()] = ["beep"]
        print(f"å·²æ·»åŠ  {len(words)} å€‹è‡ªå®šç¾©è©žå½™åˆ°éŽæ¿¾æ¸…å–®")
    
    def estimate_word_duration(self, word: str) -> float:
        """æ ¹æ“šé«’è©±é•·åº¦ä¼°ç®—ç™¼éŸ³æ™‚é–“"""
        word_length = len(word)
        if word_length <= 2:
            return 0.6
        elif word_length <= 4:
            return 1.2
        else:
            return 1.8